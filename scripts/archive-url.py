#!/usr/bin/env python3
"""
Archive web content for offline reference and traceability.

Fetches a URL, converts to markdown, and stores with provenance metadata.

Usage:
    ./scripts/archive-url.py URL [--name NAME] [--type TYPE]
    ./scripts/archive-url.py https://example.com/article --name "example-article"
    ./scripts/archive-url.py https://arxiv.org/abs/2005.07143 --type paper

Options:
    --name NAME   Descriptive name for the archive directory
    --type TYPE   Source type: primary, secondary, tertiary (default: secondary)
    --dry-run     Show what would be created without making changes

Requirements:
    - requests (pip install requests)
    - html2text (pip install html2text)
"""

import sys
import re
import subprocess
from pathlib import Path
from datetime import datetime
from urllib.parse import urlparse

try:
    import requests
except ImportError:
    print("Error: requests not installed. Run: pip install requests", file=sys.stderr)
    sys.exit(1)

try:
    import html2text
except ImportError:
    html2text = None  # Will use fallback


SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
PRINTOUTS_DIR = PROJECT_ROOT / "printouts"


def fetch_url(url):
    """Fetch content from URL."""
    headers = {
        'User-Agent': 'Mozilla/5.0 (compatible; KnowledgeBase archiver)'
    }

    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        return response.text, response.headers.get('content-type', '')
    except requests.RequestException as e:
        print(f"Error fetching URL: {e}", file=sys.stderr)
        return None, None


def html_to_markdown(html_content):
    """Convert HTML to markdown."""
    if html2text:
        h = html2text.HTML2Text()
        h.ignore_links = False
        h.ignore_images = False
        h.body_width = 0  # Don't wrap lines
        return h.handle(html_content)
    else:
        # Fallback: try pandoc if available
        try:
            result = subprocess.run(
                ['pandoc', '-f', 'html', '-t', 'markdown'],
                input=html_content,
                capture_output=True,
                text=True,
                timeout=30
            )
            if result.returncode == 0:
                return result.stdout
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass

        # Simple fallback: just strip HTML tags
        import html
        text = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL)
        text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL)
        text = re.sub(r'<[^>]+>', '', text)
        text = html.unescape(text)
        return text.strip()


def generate_archive_name(url, custom_name=None):
    """Generate archive directory name."""
    today = datetime.now().strftime('%Y-%m-%d')

    if custom_name:
        # Sanitize custom name
        name = re.sub(r'[^\w\-]', '-', custom_name.lower())
        name = re.sub(r'-+', '-', name).strip('-')
    else:
        # Generate from URL
        parsed = urlparse(url)
        domain = parsed.netloc.replace('www.', '').split('.')[0]
        path = parsed.path.strip('/').split('/')[-1] if parsed.path else 'index'
        path = re.sub(r'[^\w\-]', '-', path)[:30]
        name = f"{domain}-{path}" if path else domain

    return f"{today}--{name}"


def create_source_yaml(url, archive_name, source_type='secondary'):
    """Create SOURCE.yaml content."""
    today = datetime.now().strftime('%Y-%m-%d')

    return f"""# Archive Source Metadata
# Auto-generated by archive-url.py

source:
  url: "{url}"
  accessed: "{today}"
  archived-date: "{today}"
  source-type: "{source_type}"

description: |
  Archived web content from {urlparse(url).netloc}.
  Retrieved and converted to markdown for offline reference.

files:
  - name: "content.md"
    description: "Main page content converted to markdown"

archive-metadata:
  tool: "scripts/archive-url.py"
  generated: "{today}"
"""


def main():
    args = sys.argv[1:]

    if not args or '--help' in args or '-h' in args:
        print(__doc__)
        sys.exit(0)

    # Parse arguments
    url = None
    custom_name = None
    source_type = 'secondary'
    dry_run = '--dry-run' in args

    i = 0
    while i < len(args):
        if args[i] == '--name' and i + 1 < len(args):
            custom_name = args[i + 1]
            i += 2
        elif args[i] == '--type' and i + 1 < len(args):
            source_type = args[i + 1]
            i += 2
        elif args[i] == '--dry-run':
            i += 1
        elif not args[i].startswith('--'):
            url = args[i]
            i += 1
        else:
            i += 1

    if not url:
        print("Error: URL required", file=sys.stderr)
        print("Usage: ./scripts/archive-url.py URL [--name NAME]")
        sys.exit(1)

    # Validate URL
    if not url.startswith(('http://', 'https://')):
        print(f"Error: Invalid URL: {url}", file=sys.stderr)
        sys.exit(1)

    # Generate archive name
    archive_name = generate_archive_name(url, custom_name)
    archive_dir = PRINTOUTS_DIR / archive_name

    print(f"Archiving: {url}")
    print(f"Target: {archive_dir}")

    if dry_run:
        print(f"\n[Dry run] Would create:")
        print(f"  {archive_dir}/")
        print(f"  {archive_dir}/content.md")
        print(f"  {archive_dir}/SOURCE.yaml")
        return

    # Check if already exists
    if archive_dir.exists():
        print(f"Warning: Directory already exists: {archive_dir}", file=sys.stderr)
        response = input("Overwrite? [y/N] ")
        if response.lower() != 'y':
            print("Aborted.")
            sys.exit(0)

    # Fetch content
    print("Fetching content...")
    html_content, content_type = fetch_url(url)

    if not html_content:
        print("Failed to fetch content.", file=sys.stderr)
        sys.exit(1)

    # Convert to markdown
    print("Converting to markdown...")
    if 'html' in content_type.lower():
        markdown_content = html_to_markdown(html_content)
    else:
        # Assume already text/markdown
        markdown_content = html_content

    # Create archive directory
    archive_dir.mkdir(parents=True, exist_ok=True)

    # Write content
    content_file = archive_dir / "content.md"
    with open(content_file, 'w', encoding='utf-8') as f:
        f.write(f"# Archived: {url}\n\n")
        f.write(f"*Archived on {datetime.now().strftime('%Y-%m-%d')}*\n\n")
        f.write("---\n\n")
        f.write(markdown_content)

    # Write SOURCE.yaml
    source_file = archive_dir / "SOURCE.yaml"
    with open(source_file, 'w', encoding='utf-8') as f:
        f.write(create_source_yaml(url, archive_name, source_type))

    print(f"\nArchived successfully!")
    print(f"  Content: {content_file}")
    print(f"  Source:  {source_file}")
    print(f"\nTo reference in YAML entries:")
    print(f'  local-path: "{archive_dir.relative_to(PROJECT_ROOT)}/content.md"')


if __name__ == "__main__":
    main()
